{
    "Pandas with Pyplot": {
        "prefix": "pp",
        "body": [
            "# %%",
            "import numpy as np",
            "import pandas as pd",
            "import matplotlib.pyplot as plt",
            "%matplotlib inline",
            "# %%",
            "df = pd.read_csv(\"$1\")"
        ],
        "description": "Pandas with matplotlib",
        "scope": "python"
    },
    "Pandas with Sns": {
        "prefix": "ps",
        "body": [
            "# %%",
            "import numpy as np",
            "import pandas as pd",
            "import matplotlib.pyplot as plt",
            "import seaborn as sns",
            "%matplotlib inline",
            "# %%",
            "df = pd.read_csv(\"$1\")"
        ],
        "description": "Pandas with seaborn",
        "scope": "python"
    },
    "Create Pandas Dataframe": {
        "prefix": "pd",
        "body": [
            "# %%",
            "import numpy as np",
            "import pandas as pd",
            "# %%",
            "df = pd.read_csv(\"$1\")"
        ],
        "description": "Create Pandas Dataframe",
        "scope": "python"
    },
    "Create cell": {
        "prefix": "c",
        "body": [
            "# %%",
            "$1"
        ],
        "description": "Create code cell(# %%)",
        "scope": "python"
    },
    "Create Markdown Cell": {
        "prefix": "cc",
        "body": [
            "# %% [markdown]",
            "'''",
            "$1",
            "'''"
        ],
        "description": "Create markdown cell (# %% [markdown])",
        "scope": "python"
    },
    "Ref Line": {
        "prefix": "r",
        "body": [
            "# Ref: $1"
        ],
        "description": "Adds 'Ref line'",
        "scope": "python"
    },
    "Make Classification Dataset": {
        "prefix": "ds-c",
        "body": [
            "X,y = make_classification(",
            "    n_samples = 1000,",
            "    n_features = 5,",
            "    n_informative = 5,",
            "    n_redundant = 0,",
            "    n_classes = 2,",
            ")"
        ],
        "description": "Create classification dataset",
        "scope": "python"
    },
    "Make Regression Dataset": {
        "prefix": "ds-r",
        "body": [
            "X,y = make_classification(",
            "    n_samples = 1000",
            "    n_features = 5",
            "    n_informative = 5",
            "    bias = 0.2",
            ")"
        ],
        "description": "Create classification dataset",
        "scope": "python"
    },
    "Simple Linear Regression NB": {
        "prefix": "ml-r-slr",
        "body": [
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "",
            "from sklearn.metrics import r2_score",
            "from sklearn.model_selection import train_test_split",
            "from sklearn.linear_model import LinearRegression",
            "",
            "import pandas as pd",
            "import numpy as np",
            "import matplotlib.pyplot as pl",
            "# %%",
            "dataset = pd.read_csv(\"$1\") # Other type of file could be used which contains tabular data",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, :-1]",
            "y = dataset.iloc[:, -1]",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997",
            ")",
            "# %%",
            "model = LinearRegression(",
            "    normalize=True, fit_intercept=True, n_jobs=-1).fit(X_train, y_train)",
            "# %%",
            "y_predicted = model.predict(X_test)",
            "# %%",
            "r2_score(y_predicted, y_test)",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(model, 'model/model.joblib')",
            "loaded_model = load('model/model.joblib')"
        ],
        "description": "Simple Linear Regression Snippet",
        "scope": "python"
    },
    "Multiple Linear Regression NB": {
        "prefix": "ml-r-mlr",
        "body": [
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.preprocessing import OneHotEncoder, StandardScaler",
            "from sklearn.metrics import r2_score",
            "from sklearn.linear_model import LinearRegression",
            "from sklearn.compose import ColumnTransformer",
            "import numpy as np",
            "import pandas as pd",
            "import matplotlib.pyplot as plt",
            "from sklearn.model_selection import train_test_split",
            "# %%",
            "dataset = pd.read_csv(\"$1\") # Other type of file could be used which contains tabular data",
            "# %%",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, :-1]",
            "y = dataset.iloc[:, -1]",
            "# %%",
            "state_encoder = OneHotEncoder()",
            "ct = ColumnTransformer([",
            "#    Do Required Transformation(s) here, you are not limited just with this can do what ever is required",
            "$2",
            "], remainder='passthrough')",
            "X = np.array(ct.fit_transform(X))",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "# %%",
            "model = LinearRegression().fit(X_train, y_train)",
            "# %%",
            "y_pred = model.predict(X_test)",
            "# %%",
            "r2_score(y_pred, y_test)",
            "# Other matrices could be used here",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(model, 'model/model.joblib')",
            "loaded_model = load('model/model.joblib')"
        ],
        "description": "Multiple Linear Regression Snippet",
        "scope": "python"
    },
    "Polynomial Regression NB": {
        "prefix": "ml-r-ply",
        "body": [
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import r2_score",
            "from sklearn.preprocessing import PolynomialFeatures",
            "import numpy as np",
            "import pandas as pd",
            "from sklearn.model_selection import train_test_split",
            "# %%",
            "dataset = pd.read_csv('$1') # Other type of file could be used which contains tabular data",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, 1:-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "# Do required transformation(s) for X and/or y (If required)",
            "# %%",
            "poly_reg = PolynomialFeatures(degree=$2)",
            "X_poly = poly_reg.fit_transform(X)",
            "# %%",
            "r2_score(y, lin_reg_2.predict(X_poly))",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(poly_reg, 'model/poly_reg.joblib')",
            "loaded_model = load('model/poly_reg.joblib')"
        ],
        "description": "Polynomial Regression snippet",
        "scope": "python"
    },
    "SVM Regressor with RBF kernel NB": {
        "prefix": "ml-r-svr",
        "body": [
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import r2_score",
            "from sklearn.svm import SVR",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1') # Other type of file could be used which contains tabular data",
            "# %%",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, 1:-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "# Do required transformation(s) for X and/or y (If required)",
            "# %%",
            "reg = SVR(kernel='rbf').fit(X, y)",
            "# %%",
            "y_pred = reg.predict(X)",
            "# %%",
            "r2_score(y, y_pred)",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(reg, 'model/reg.joblib')",
            "loaded_model = load('model/reg.joblib')"
        ],
        "description": "SVM Regressor with RBF kernel",
        "scope": "python"
    },
    "Decision Tree Regressor NB": {
        "prefix": "ml-r-dtr",
        "body": [
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import r2_score",
            "from sklearn.tree import DecisionTreeRegressor",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1') # Other type of file could be used which contains tabular data",
            "# %%",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, 1:-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "# Do required transformation(s) for X and/or y (If required)",
            "# %%",
            "regressor = DecisionTreeRegressor(random_state=997).fit(X, y)",
            "# %%",
            "y_pred = regressor.predict(X)",
            "# %%",
            "r2_score(y, y_pred)",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(regressor, 'model/regressor.joblib')",
            "loaded_model = load('model/regressor.joblib')"
        ],
        "description": "Decision Tree Regressor Snippet",
        "scope": "python"
    },
    "Random Forest Regressor NB": {
        "prefix": "ml-r-rfr",
        "body": [
            "# %%",
            "from joblib import dump, load", 
            "from pathlib import Path", 
            "from sklearn.metrics import r2_score",
            "from sklearn.ensemble import RandomForestRegressor",
            "import pandas as pd",
            "import matplotlib.pyplot as plt",
            "# %%",
            "dataset = pd.read_csv('$1') # Other type of file could be used which contains tabular data",
            "# %%",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, 1:-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "# Do required transformation(s) for X and/or y (If required)",
            "# %%",
            "regressor = RandomForestRegressor(n_estimators=10, random_state=0).fit(X, y)",
            "# %%",
            "y_pred = regressor.predict(X)",
            "# %%",
            "r2_score(y, y_pred)",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(regressor, 'model/regressor.joblib')",
            "loaded_model = load('model/regressor.joblib')"
        ],
        "description": "Random Forest Regressor Snippet",
        "scope": "python"
    },
    "Logistic Regression Classification NB": {
        "prefix": "ml-c-lr",
        "body": [
            "# %% [markdown]",
            "'''",
            "### Logistic Regression",
            "'''",
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import (",
            "    f1_score,",
            "    accuracy_score,",
            "    recall_score,",
            "    confusion_matrix,",
            "    auc,",
            "    roc_curve,",
            ")",
            "from sklearn.linear_model import LogisticRegression",
            "import pandas as pd",
            "from sklearn.model_selection import train_test_split",
            "from sklearn.preprocessing import StandardScaler",
            "# %%",
            "dataset = pd.read_csv('$1')",
            "# %%",
            "dataset.describe()",
            "# %%",
            "dataset.head()",
            "# %%",
            "dataset.info()",
            "# %%",
            "X = dataset[['$2']]",
            "y = dataset[['$3']]",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, random_state=997, test_size=0.2",
            ")",
            "# %%",
            "# Better scale all features",
            "sc_x = StandardScaler()",
            "scalled_x_train = sc_x.fit_transform(X_train)",
            "# Do All required transformations as they are data specific",
            "# %%",
            "classifier = LogisticRegression(random_state=997).fit(scalled_x_train, y_train)",
            "# %%",
            "scalled_x_test = sc_x.transform(X_test)",
            "y_pred = classifier.predict(scalled_x_test)",
            "# %%",
            "fpr, tpr, _ = roc_curve(y_test, y_pred)",
            "auc(fpr, tpr)",
            "# %%",
            "print(f'Confusion Matrix:{confusion_matrix(y_test, y_pred)}')",
            "print(f'F1 Score:{f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Logistic Regression",
        "scope": "python"
    },
    "K-Nearest Neighbors (K-NN) Classification NB": {
        "prefix": "ml-c-knn",
        "body": [
            "# %% [markdown]",
            "'''",
            "K-Nearest Neighbors (K-NN) Classification",
            "'''",
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix, auc, roc_curve",
            "from sklearn.neighbors import KNeighborsClassifier",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import numpy as np",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1')",
            "# %%",
            "dataset.describe()",
            "# %%",
            "dataset.head()",
            "# %%",
            "dataset.info()",
            "# %%",
            "X = dataset[['$2']]",
            "y = dataset[['$3']]",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, random_state=997, test_size=0.2)",
            "# %%",
            "sc_x = StandardScaler()",
            "scalled_x_train = sc_x.fit_transform(X_train)",
            "# Do All required transformations as they are data specific",
            "# %%",
            "classifier = KNeighborsClassifier(",
            "    n_neighbors=5, n_jobs=-1).fit(scalled_x_train, y_train)",
            "# %%",
            "scalled_x_test = sc_x.transform(X_test)",
            "y_pred = classifier.predict(scalled_x_test)",
            "# %%",
            "fpr, tpr, _ = roc_curve(y_test, y_pred)",
            "auc(fpr, tpr)",
            "# %%",
            "print(f'Confusion Matrix:{confusion_matrix(y_test, y_pred)}')",
            "print(f'F1 Score:{f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "K-Nearest Neighbors (K-NN) Classification",
        "scope": "python"
    },
    "Support Vector Machine (SVM) Classification NB": {
        "prefix": "ml-c-svm",
        "body": [
            "# %% [markdown]",
            "'''",
            "Support Vector Machine (SVM) Classification",
            "'''",
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.svm import SVC",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1')",
            "# %%",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "# %%",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "# Do All required transformations as they are data specific",
            "# %%",
            "classifier = SVC(kernel='rbf', random_state=997).fit(scalled_x_train, y_train)",
            "# %%",
            "y_pred = classifier.predict(scalled_x_test)",
            "# %%",
            "confusion_matrix(y_test, y_pred)",
            "# %%",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Support Vector Machine (SVM) Classification",
        "scope": "python"
    },
    "Kernel SVM Classification NB": {
        "prefix": "ml-c-ksvm",
        "body": [
            "# %% [markdown]",
            "'''",
            "Kernel SVM Classification",
            "'''",
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.svm import SVC",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1')",
            "# %%",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "",
            "# %%",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "# %%",
            "classifier = SVC(kernel='rbf', random_state=997).fit(scalled_x_train, y_train)",
            "# %%",
            "y_pred = classifier.predict(scalled_x_test)",
            "# %%",
            "confusion_matrix(y_test, y_pred)",
            "# %%",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Kernel SVM Classification",
        "scope": "python"
    },
    "Gaussian Naive Bayes NB": {
        "prefix": "ml-c-gnb",
        "body": [
            "# %% [markdown]",
            "'''",
            "Gaussian Naive Bayes",
            "'''",
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.naive_bayes import GaussianNB",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1')",
            "# %%",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "# %%",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "# %%",
            "classifier = GaussianNB().fit(scalled_x_train, y_train)",
            "# %%",
            "y_pred = classifier.predict(scalled_x_test)",
            "# %%",
            "confusion_matrix(y_test, y_pred)",
            "# %%",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Gaussian Naive Bayes",
        "scope": "python"
    },
    "Multinomial Naive Bayes NB": {
        "prefix": "ml-c-mnb",
        "body": [
            "# %% [markdown]",
            "'''",
            "Multinomial Naive Bayes",
            "'''",
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.naive_bayes import MultinomialNB",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1')",
            "# %%",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "# %%",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "# %%",
            "classifier = MultinomialNB().fit(scalled_x_train, y_train)",
            "# %%",
            "y_pred = classifier.predict(scalled_x_test)",
            "# %%",
            "confusion_matrix(y_test, y_pred)",
            "# %%",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Multinomial Naive Bayes",
        "scope": "python"
    },
    "Decision Tree Classification NB": {
        "prefix": "ml-c-dtc",
        "body": [
            "# %% [markdown]",
            "'''",
            "Decision Tree Classification",
            "'''",
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.tree import DecisionTreeClassifier",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import numpy as np",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1')",
            "# %%",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "# %%",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "",
            "# %%",
            "classifier = DecisionTreeClassifier(",
            "    random_state=997, criterion='entropy').fit(scalled_x_train, y_train)",
            "# %%",
            "y_pred = classifier.predict(scalled_x_test)",
            "# %%",
            "confusion_matrix(y_test, y_pred)",
            "# %%",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Decision Tree Classification",
        "scope": "python"
    },
    "Random Forest Classification NB": {
        "prefix": "ml-c-rfc",
        "body": [
            "# %% [markdown]",
            "'''",
            "### Random Forest Classification",
            "'''",
            "# %%",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.ensemble import RandomForestClassifier",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "# %%",
            "dataset = pd.read_csv('$1')",
            "# %%",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "# %%",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "# %%",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "# %%",
            "classifier = RandomForestClassifier(",
            "    n_estimators=45, criterion='entropy', n_jobs=-1).fit(scalled_x_train, y_train)",
            "# %%",
            "y_pred = classifier.predict(scalled_x_test)",
            "# %%",
            "confusion_matrix(y_test, y_pred)",
            "# %%",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Random Forest Classification",
        "scope": "python"
    },
    "Simple Linear Regression ": {
        "prefix": "ml-r-slr",
        "body": [
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import r2_score",
            "import pandas as pd",
            "import numpy as np",
            "import matplotlib.pyplot as pl",
            "from sklearn.model_selection import train_test_split",
            "from sklearn.linear_model import LinearRegression",
            "dataset = pd.read_csv(\"$1\") # Other type of file could be used which contains tabular data",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, :-1]",
            "y = dataset.iloc[:, -1]",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997",
            ")",
            "model = LinearRegression(",
            "    normalize=True, fit_intercept=True, n_jobs=-1).fit(X_train, y_train)",
            "y_predicted = model.predict(X_test)",
            "r2_score(y_predicted, y_test)",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(model, 'model/model.joblib')",
            "loaded_model = load('model/model.joblib')"
        ],
        "description": "Simple Linear Regression Snippet",
        "scope": "python"
    },
    "Multiple Linear Regression": {
        "prefix": "ml-r-mlr",
        "body": [
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.preprocessing import OneHotEncoder, StandardScaler",
            "from sklearn.metrics import r2_score",
            "from sklearn.linear_model import LinearRegression",
            "from sklearn.compose import ColumnTransformer",
            "import numpy as np",
            "import pandas as pd",
            "import matplotlib.pyplot as plt",
            "from sklearn.model_selection import train_test_split",
            "dataset = pd.read_csv(\"$1\") # Other type of file could be used which contains tabular data",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, :-1]",
            "y = dataset.iloc[:, -1]",
            "state_encoder = OneHotEncoder()",
            "ct = ColumnTransformer([",
            "#    Do Required Transformation(s) here, you are not limited just with this can do what ever is required",
            "$2",
            "], remainder='passthrough')",
            "X = np.array(ct.fit_transform(X))",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "model = LinearRegression().fit(X_train, y_train)",
            "y_pred = model.predict(X_test)",
            "r2_score(y_pred, y_test)",
            "# Other matrices could be used here",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(model, 'model/model.joblib')",
            "loaded_model = load('model/model.joblib')"
        ],
        "description": "Multiple Linear Regression Snippet",
        "scope": "python"
    },
    "Polynomial Regression": {
        "prefix": "ml-r-ply",
        "body": [
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import r2_score",
            "from sklearn.preprocessing import PolynomialFeatures",
            "import numpy as np",
            "import pandas as pd",
            "from sklearn.model_selection import train_test_split",
            "dataset = pd.read_csv('$1') # Other type of file could be used which contains tabular data",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, 1:-1].values",
            "y = dataset.iloc[:, -1].values",
            "# Do required transformation(s) for X and/or y (If required)",
            "poly_reg = PolynomialFeatures(degree=$2)",
            "X_poly = poly_reg.fit_transform(X)",
            "r2_score(y, lin_reg_2.predict(X_poly))",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(poly_reg, 'model/poly_reg.joblib')",
            "loaded_model = load('model/poly_reg.joblib')"
        ],
        "description": "Polynomial Regression snippet",
        "scope": "python"
    },
    "SVM Regressor with RBF kernel": {
        "prefix": "ml-r-svr",
        "body": [
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import r2_score",
            "from sklearn.svm import SVR",
            "import pandas as pd",
            "dataset = pd.read_csv('$1') # Other type of file could be used which contains tabular data",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, 1:-1].values",
            "y = dataset.iloc[:, -1].values",
            "# Do required transformation(s) for X and/or y (If required)",
            "reg = SVR(kernel='rbf').fit(X, y)",
            "y_pred = reg.predict(X)",
            "r2_score(y, y_pred)",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(reg, 'model/reg.joblib')",
            "loaded_model = load('model/reg.joblib')"
        ],
        "description": "SVM Regressor with RBF kernel",
        "scope": "python"
    },
    "Decision Tree Regressor": {
        "prefix": "ml-r-dtr",
        "body": [
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import r2_score",
            "from sklearn.tree import DecisionTreeRegressor",
            "import pandas as pd",
            "dataset = pd.read_csv('$1') # Other type of file could be used which contains tabular data",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, 1:-1].values",
            "y = dataset.iloc[:, -1].values",
            "# Do required transformation(s) for X and/or y (If required)",
            "regressor = DecisionTreeRegressor(random_state=997).fit(X, y)",
            "y_pred = regressor.predict(X)",
            "r2_score(y, y_pred)",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(regressor, 'model/regressor.joblib')",
            "loaded_model = load('model/regressor.joblib')"
        ],
        "description": "Decision Tree Regressor Snippet",
        "scope": "python"
    },
    "Random Forest Regressor": {
        "prefix": "ml-r-rfr",
        "body": [
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import r2_score",
            "from sklearn.ensemble import RandomForestRegressor",
            "import pandas as pd",
            "import matplotlib.pyplot as plt",
            "dataset = pd.read_csv('$1') # Other type of file could be used which contains tabular data",
            "# Target column must be last to work below all cell's code correctly, If you don't have your target colum last then make necessary changes to below two lines of code",
            "X = dataset.iloc[:, 1:-1].values",
            "y = dataset.iloc[:, -1].values",
            "# Do required transformation(s) for X and/or y (If required)",
            "regressor = RandomForestRegressor(n_estimators=10, random_state=0).fit(X, y)",
            "y_pred = regressor.predict(X)",
            "r2_score(y, y_pred)",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(regressor, 'model/regressor.joblib')",
            "loaded_model = load('model/regressor.joblib')"
        ],
        "description": "Random Forest Regressor Snippet",
        "scope": "python"
    },
    "Logistic Regression Classification": {
        "prefix": "ml-c-lr",
        "body": [
            "'''",
            "### Logistic Regression",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import (",
            "    f1_score,",
            "    accuracy_score,",
            "    recall_score,",
            "    confusion_matrix,",
            "    auc,",
            "    roc_curve,",
            ")",
            "from sklearn.linear_model import LogisticRegression",
            "import pandas as pd",
            "from sklearn.model_selection import train_test_split",
            "from sklearn.preprocessing import StandardScaler",
            "dataset = pd.read_csv('$1')",
            "dataset.describe()",
            "dataset.head()",
            "dataset.info()",
            "X = dataset[['$2']]",
            "y = dataset[['$3']]",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, random_state=997, test_size=0.2",
            ")",
            "# Better scale all features",
            "sc_x = StandardScaler()",
            "scalled_x_train = sc_x.fit_transform(X_train)",
            "# Do All required transformations as they are data specific",
            "classifier = LogisticRegression(random_state=997).fit(scalled_x_train, y_train)",
            "scalled_x_test = sc_x.transform(X_test)",
            "y_pred = classifier.predict(scalled_x_test)",
            "fpr, tpr, _ = roc_curve(y_test, y_pred)",
            "auc(fpr, tpr)",
            "print(f'Confusion Matrix:{confusion_matrix(y_test, y_pred)}')",
            "print(f'F1 Score:{f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Logistic Regression",
        "scope": "python"
    },
    "K-Nearest Neighbors (K-NN) Classification": {
        "prefix": "ml-c-knn",
        "body": [
            "'''",
            "K-Nearest Neighbors (K-NN) Classification",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix, auc, roc_curve",
            "from sklearn.neighbors import KNeighborsClassifier",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import numpy as np",
            "import pandas as pd",
            "dataset = pd.read_csv('$1')",
            "dataset.describe()",
            "dataset.head()",
            "dataset.info()",
            "X = dataset[['$2']]",
            "y = dataset[['$3']]",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, random_state=997, test_size=0.2)",
            "sc_x = StandardScaler()",
            "scalled_x_train = sc_x.fit_transform(X_train)",
            "# Do All required transformations as they are data specific",
            "classifier = KNeighborsClassifier(",
            "    n_neighbors=5, n_jobs=-1).fit(scalled_x_train, y_train)",
            "scalled_x_test = sc_x.transform(X_test)",
            "y_pred = classifier.predict(scalled_x_test)",
            "fpr, tpr, _ = roc_curve(y_test, y_pred)",
            "auc(fpr, tpr)",
            "print(f'Confusion Matrix:{confusion_matrix(y_test, y_pred)}')",
            "print(f'F1 Score:{f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "K-Nearest Neighbors (K-NN) Classification",
        "scope": "python"
    },
    "Support Vector Machine (SVM) Classification": {
        "prefix": "ml-c-svm",
        "body": [
            "'''",
            "Support Vector Machine (SVM) Classification",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.svm import SVC",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "",
            "import pandas as pd",
            "dataset = pd.read_csv('$1')",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "# Do All required transformations as they are data specific",
            "classifier = SVC(kernel='rbf', random_state=997).fit(scalled_x_train, y_train)",
            "y_pred = classifier.predict(scalled_x_test)",
            "confusion_matrix(y_test, y_pred)",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Support Vector Machine (SVM) Classification",
        "scope": "python"
    },
    "Kernel SVM Classification": {
        "prefix": "ml-c-ksvm",
        "body": [
            "'''",
            "Kernel SVM Classification",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.svm import SVC",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "dataset = pd.read_csv('$1')",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "classifier = SVC(kernel='rbf', random_state=997).fit(scalled_x_train, y_train)",
            "y_pred = classifier.predict(scalled_x_test)",
            "confusion_matrix(y_test, y_pred)",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Kernel SVM Classification",
        "scope": "python"
    },
    "Gaussian Naive Bayes": {
        "prefix": "ml-c-gnb",
        "body": [
            "'''",
            "Gaussian Naive Bayes",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.naive_bayes import GaussianNB",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "dataset = pd.read_csv('$1')",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "classifier = GaussianNB().fit(scalled_x_train, y_train)",
            "y_pred = classifier.predict(scalled_x_test)",
            "confusion_matrix(y_test, y_pred)",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Gaussian Naive Bayes",
        "scope": "python"
    },
    "Multinomial Naive Bayes": {
        "prefix": "ml-c-mnb",
        "body": [
            "'''",
            "Multinomial Naive Bayes",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.naive_bayes import MultinomialNB",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "dataset = pd.read_csv('$1')",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "classifier = MultinomialNB().fit(scalled_x_train, y_train)",
            "y_pred = classifier.predict(scalled_x_test)",
            "confusion_matrix(y_test, y_pred)",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Multinomial Naive Bayes",
        "scope": "python"
    },
    "Decision Tree Classification": {
        "prefix": "ml-c-dtc",
        "body": [
            "'''",
            "Decision Tree Classification",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.tree import DecisionTreeClassifier",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import numpy as np",
            "import pandas as pd",
            "dataset = pd.read_csv('$1')",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "",
            "classifier = DecisionTreeClassifier(",
            "    random_state=997, criterion='entropy').fit(scalled_x_train, y_train)",
            "y_pred = classifier.predict(scalled_x_test)",
            "confusion_matrix(y_test, y_pred)",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Decision Tree Classification",
        "scope": "python"
    },
    "Random Forest Classification": {
        "prefix": "ml-c-rfc",
        "body": [
            "'''",
            "### Random Forest Classification",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.ensemble import RandomForestClassifier",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "dataset = pd.read_csv('$1')",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "classifier = RandomForestClassifier(",
            "    n_estimators=45, criterion='entropy', n_jobs=-1).fit(scalled_x_train, y_train)",
            "y_pred = classifier.predict(scalled_x_test)",
            "confusion_matrix(y_test, y_pred)",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Random Forest Classification",
        "scope": "python"
    },
    "Text Classification": {
        "prefix": "ml-c-txt",
        "body": [
            "'''",
            "### Random Forest Text Classification",
            "'''",
            "from joblib import dump, load",
            "from pathlib import Path",
            "from sklearn.metrics import f1_score, accuracy_score, recall_score, confusion_matrix",
            "from sklearn.ensemble import RandomForestClassifier",
            "from sklearn.preprocessing import StandardScaler",
            "from sklearn.model_selection import train_test_split",
            "import pandas as pd",
            "dataset = pd.read_csv('$1')",
            "X = dataset.iloc[:, :-1].values",
            "y = dataset.iloc[:, -1].values",
            "X_train, X_test, y_train, y_test = train_test_split(",
            "    X, y, test_size=0.2, random_state=997)",
            "ss = StandardScaler()",
            "scalled_x_train = ss.fit_transform(X_train)",
            "scalled_x_test = ss.transform(X_test)",
            "classifier = RandomForestClassifier(",
            "    n_estimators=45, criterion='entropy', n_jobs=-1).fit(scalled_x_train, y_train)",
            "y_pred = classifier.predict(scalled_x_test)",
            "confusion_matrix(y_test, y_pred)",
            "print(f'F1 Score: {f1_score(y_test, y_pred)}')",
            "print(f'Accuracy Score: {accuracy_score(y_test, y_pred)}')",
            "print(f'Recall Score: {recall_score(y_test, y_pred)}')",
            "model_dir_path = Path('model')",
            "model_dir_path.mkdir(exist_ok=True)",
            "dump(classifier, 'model/classifier.joblib')",
            "loaded_model = load('model/classifier.joblib')"
        ],
        "description": "Random Forest Classification",
        "scope": "python"
    }
}